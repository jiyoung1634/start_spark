{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51193550-e77e-4e61-9d12-4593a6e88a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://788ab5d9f938:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>classificationExample1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f001e48cf10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"classificationExample1\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4bc57-ffeb-4fd4-90ac-34d2bc92b9a4",
   "metadata": {},
   "source": [
    "# 타이타닉 데이터를 이용한 생존여부 예측 모델\n",
    "## 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca9770f-f720-44db-b8d2-b2a30a08c455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|Gender| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 로드\n",
    "data = spark.read.csv('learning_spark_data/titanic.csv', header=True, inferSchema=True)\n",
    "# 데이터 확인\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f2d207-631b-4f6c-94d3-df16ed375457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+------+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Gender|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+------+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|     0|177|    0|    0|     0|   0|  687|       2|\n",
      "+-----------+--------+------+----+------+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum, when, isnan\n",
    "\n",
    "# 결측치 처리\n",
    "null_counts = data.select(\n",
    "    [\n",
    "        sum( when(col(c).isNull() | isnan(c), 1).otherwise(0) ).alias(c)\n",
    "        for c in data.columns\n",
    "    ]\n",
    ")\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8e91f5f-7dd2-4905-b21a-e20206e8897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+\n",
      "|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|\n",
      "+--------+------+------+----+-----+-----+-------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|\n",
      "+--------+------+------+----+-----+-----+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "data_1 = data.select('Survived', 'Pclass', 'Gender', 'Age', 'SibSp', 'Parch', 'Fare')\n",
    "data_1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc70d58-6d6e-4c56-9073-12ba98ffa67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# age 결측치 처리 - 평균값으로 대체\n",
    "mean_age = data_1.select('Age').agg({\n",
    "    \"Age\":\"mean\"\n",
    "}).collect()[0][0]\n",
    "mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a7ddbb8-40d7-4420-abc8-534725909403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+-----------------+-----+-----+-------+\n",
      "|Survived|Pclass|Gender|              Age|SibSp|Parch|   Fare|\n",
      "+--------+------+------+-----------------+-----+-----+-------+\n",
      "|       0|     3|  male|             22.0|    1|    0|   7.25|\n",
      "|       1|     1|female|             38.0|    1|    0|71.2833|\n",
      "|       1|     3|female|             26.0|    0|    0|  7.925|\n",
      "|       1|     1|female|             35.0|    1|    0|   53.1|\n",
      "|       0|     3|  male|             35.0|    0|    0|   8.05|\n",
      "|       0|     3|  male|29.69911764705882|    0|    0| 8.4583|\n",
      "|       0|     1|  male|             54.0|    0|    0|51.8625|\n",
      "|       0|     3|  male|              2.0|    3|    1| 21.075|\n",
      "|       1|     3|female|             27.0|    0|    2|11.1333|\n",
      "|       1|     2|female|             14.0|    1|    0|30.0708|\n",
      "+--------+------+------+-----------------+-----+-----+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_1 = data_1.fillna({'Age':mean_age})\n",
    "data_1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "417324ca-4d1b-4667-bdc9-daf52dec0edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78579525-2f4e-4dcc-bbb0-f3eac1944ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+-----------------+-----+-----+-------+----------+\n",
      "|Survived|Pclass|Gender|              Age|SibSp|Parch|   Fare|SexIndexer|\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+\n",
      "|       0|     3|  male|             22.0|    1|    0|   7.25|       0.0|\n",
      "|       1|     1|female|             38.0|    1|    0|71.2833|       1.0|\n",
      "|       1|     3|female|             26.0|    0|    0|  7.925|       1.0|\n",
      "|       1|     1|female|             35.0|    1|    0|   53.1|       1.0|\n",
      "|       0|     3|  male|             35.0|    0|    0|   8.05|       0.0|\n",
      "|       0|     3|  male|29.69911764705882|    0|    0| 8.4583|       0.0|\n",
      "|       0|     1|  male|             54.0|    0|    0|51.8625|       0.0|\n",
      "|       0|     3|  male|              2.0|    3|    1| 21.075|       0.0|\n",
      "|       1|     3|female|             27.0|    0|    2|11.1333|       1.0|\n",
      "|       1|     2|female|             14.0|    1|    0|30.0708|       1.0|\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 인코딩 StringIndexer\n",
    "indexer = StringIndexer(inputCol='Gender', outputCol='SexIndexer')\n",
    "data_1 = indexer.fit(data_1).transform(data_1)\n",
    "data_1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0cfffdf-ad79-41f5-87f1-4773f7a4c99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|Survived|\n",
      "+--------------------+--------+\n",
      "|[3.0,0.0,22.0,1.0...|       0|\n",
      "|[1.0,1.0,38.0,1.0...|       1|\n",
      "|[3.0,1.0,26.0,0.0...|       1|\n",
      "|[1.0,1.0,35.0,1.0...|       1|\n",
      "|[3.0,0.0,35.0,0.0...|       0|\n",
      "|[3.0,0.0,29.69911...|       0|\n",
      "|[1.0,0.0,54.0,0.0...|       0|\n",
      "|[3.0,0.0,2.0,3.0,...|       0|\n",
      "|[3.0,1.0,27.0,0.0...|       1|\n",
      "|[2.0,1.0,14.0,1.0...|       1|\n",
      "+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FeatureVector 생성\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['Pclass', 'SexIndexer', 'Age', 'SibSp', 'Parch', 'Fare'],\n",
    "    outputCol='features'\n",
    ")\n",
    "data_1 = assembler.transform(data_1)\n",
    "data_1.select('features', 'Survived').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff6e8aaf-7b02-421e-bbd3-021943089754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+------+----------+--------------------+\n",
      "|Survived|Pclass|Gender| Age|SibSp|Parch|  Fare|SexIndexer|            features|\n",
      "+--------+------+------+----+-----+-----+------+----------+--------------------+\n",
      "|       0|     1|female| 2.0|    1|    2|151.55|       1.0|[1.0,1.0,2.0,1.0,...|\n",
      "|       0|     1|female|25.0|    1|    2|151.55|       1.0|[1.0,1.0,25.0,1.0...|\n",
      "|       0|     1|  male|18.0|    1|    0| 108.9|       0.0|[1.0,0.0,18.0,1.0...|\n",
      "|       0|     1|  male|19.0|    1|    0|  53.1|       0.0|[1.0,0.0,19.0,1.0...|\n",
      "|       0|     1|  male|19.0|    3|    2| 263.0|       0.0|[1.0,0.0,19.0,3.0...|\n",
      "+--------+------+------+----+-----+-----+------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+--------------------+\n",
      "|Survived|Pclass|Gender|              Age|SibSp|Parch|   Fare|SexIndexer|            features|\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+--------------------+\n",
      "|       0|     1|female|             50.0|    0|    0|28.7125|       1.0|[1.0,1.0,50.0,0.0...|\n",
      "|       0|     1|  male|             21.0|    0|    1|77.2875|       0.0|[1.0,0.0,21.0,0.0...|\n",
      "|       0|     1|  male|             24.0|    0|    0|   79.2|       0.0|[1.0,0.0,24.0,0.0...|\n",
      "|       0|     1|  male|             29.0|    0|    0|   30.0|       0.0|[1.0,0.0,29.0,0.0...|\n",
      "|       0|     1|  male|29.69911764705882|    0|    0|  26.55|       0.0|[1.0,0.0,29.69911...|\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 분할\n",
    "train_data, test_data = data_1.randomSplit([0.8, 0.2], seed=42)\n",
    "train_data.show(5), test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7961f1bb-a3d8-4625-8d9e-4e88ffb9d669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----------+\n",
      "|            features|Survived|prediction|\n",
      "+--------------------+--------+----------+\n",
      "|[1.0,1.0,50.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,21.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,24.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,29.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,29.69911...|       0|       1.0|\n",
      "+--------------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='Survived')\n",
    "lr_model = lr.fit(train_data)\n",
    "predic = lr_model.transform(test_data)\n",
    "predic.select('features', 'Survived', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7598556-e07c-4d97-97f7-59bb886c4bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----+\n",
      "|Survived|prediction|count|\n",
      "+--------+----------+-----+\n",
      "|       1|       0.0|   16|\n",
      "|       0|       0.0|   72|\n",
      "|       1|       1.0|   45|\n",
      "|       0|       1.0|   12|\n",
      "+--------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predic.select('Survived', 'prediction').groupBy('Survived', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08c00ed8-5005-4831-b9b9-f256e6f683b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "comp = predic.withColumn('correct', expr('case when Survived = prediction then 1 else 0 end'))\n",
    "comp.where('correct=0').count()   # 틀린 거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab106358-d500-4772-92ac-8919e0767390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+-----------------+-----+-----+--------+----------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass|Gender|              Age|SibSp|Parch|    Fare|SexIndexer|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+------+-----------------+-----+-----+--------+----------+--------------------+--------------------+--------------------+----------+\n",
      "|       0|     1|female|             50.0|    0|    0| 28.7125|       1.0|[1.0,1.0,50.0,0.0...|[-1.9520233772457...|[0.12433289705143...|       1.0|\n",
      "|       0|     1|  male|             21.0|    0|    1| 77.2875|       0.0|[1.0,0.0,21.0,0.0...|[-0.5063625084573...|[0.37604662481402...|       1.0|\n",
      "|       0|     1|  male|             24.0|    0|    0|    79.2|       0.0|[1.0,0.0,24.0,0.0...|[-0.5000095386390...|[0.37753842718518...|       1.0|\n",
      "|       0|     1|  male|             29.0|    0|    0|    30.0|       0.0|[1.0,0.0,29.0,0.0...|[-0.1615540822042...|[0.45969909487698...|       1.0|\n",
      "|       0|     1|  male|29.69911764705882|    0|    0|   26.55|       0.0|[1.0,0.0,29.69911...|[-0.1231782413911...|[0.46924431750958...|       1.0|\n",
      "|       0|     1|  male|29.69911764705882|    0|    0|    31.0|       0.0|[1.0,0.0,29.69911...|[-0.1347897264619...|[0.46635349453316...|       1.0|\n",
      "|       0|     1|  male|29.69911764705882|    0|    0|221.7792|       0.0|[1.0,0.0,29.69911...|[-0.6325941832296...|[0.34692254756630...|       1.0|\n",
      "|       0|     3|female|              9.0|    1|    1| 15.2458|       1.0|[3.0,1.0,9.0,1.0,...|[-0.8294985925619...|[0.30375110057917...|       1.0|\n",
      "|       0|     3|female|             14.0|    0|    0|  7.8542|       1.0|[3.0,1.0,14.0,0.0...|[-1.1048782816873...|[0.24882696769997...|       1.0|\n",
      "|       0|     3|female|             22.0|    0|    0| 10.5167|       1.0|[3.0,1.0,22.0,0.0...|[-0.7757027387564...|[0.31524678240576...|       1.0|\n",
      "|       0|     3|female|             28.0|    1|    1|    14.4|       1.0|[3.0,1.0,28.0,1.0...|[-0.0289998254718...|[0.49275055168429...|       1.0|\n",
      "|       0|     3|female|29.69911764705882|    0|    0|  8.1375|       1.0|[3.0,1.0,29.69911...|[-0.4460134544155...|[0.39030901997152...|       1.0|\n",
      "|       1|     1|  male|             40.0|    0|    0|    31.0|       0.0|[1.0,0.0,40.0,0.0...|[0.29800553338314...|[0.57395488063056...|       0.0|\n",
      "|       1|     1|  male|             42.0|    0|    0| 26.2875|       0.0|[1.0,0.0,42.0,0.0...|[0.39433268162065...|[0.59732526764030...|       0.0|\n",
      "|       1|     1|  male|             45.0|    0|    0|   26.55|       0.0|[1.0,0.0,45.0,0.0...|[0.51969380848810...|[0.62707616571001...|       0.0|\n",
      "|       1|     2|  male|              2.0|    1|    1|    26.0|       0.0|[2.0,0.0,2.0,1.0,...|[0.37184806510138...|[0.59190546052286...|       0.0|\n",
      "|       1|     3|female|29.69911764705882|    2|    0|   23.25|       1.0|[3.0,1.0,29.69911...|[0.29463470411987...|[0.57313040472105...|       0.0|\n",
      "|       1|     3|female|             33.0|    3|    0|   15.85|       1.0|[3.0,1.0,33.0,3.0...|[0.84267221664326...|[0.69902771706049...|       0.0|\n",
      "|       1|     3|female|             38.0|    1|    5| 31.3875|       1.0|[3.0,1.0,38.0,1.0...|[0.80563898861163...|[0.69117942146816...|       0.0|\n",
      "|       1|     3|female|             63.0|    0|    0|  9.5875|       1.0|[3.0,1.0,63.0,0.0...|[0.94935152197948...|[0.72098474515652...|       0.0|\n",
      "+--------+------+------+-----------------+-----+-----+--------+----------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 틀린 데이터만 필터링\n",
    "predic.filter(col('Survived') != col('prediction')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d365cb-74be-4f96-b211-d7ab9471b6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22f2858e-bed4-41cc-b05b-60841f43a94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8068965517241379"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 평가\n",
    "comp.selectExpr('avg(correct) as accuracy').collect()[0]['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa0c67e9-3824-4253-83ad-ce2693ca796d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8664129586260734"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "eval = BinaryClassificationEvaluator(labelCol='Survived',\n",
    "                                    rawPredictionCol='rawPrediction',\n",
    "                                    metricName='areaUnderROC')\n",
    "auc = eval.evaluate(predic)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f3874b-3c1d-4a6f-8e60-8467a093deb7",
   "metadata": {},
   "source": [
    "AUROC -> X축 FPR, y축 TPR의 곡선 아래면적, 1에 가까울수록 좋은 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "386147fc-7207-4ce7-bfe7-006cc2da5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97936fc-c766-481d-865a-ae4ce291e7fc",
   "metadata": {},
   "source": [
    "# libsvm 파일 형식의 처리\n",
    "텍스트 파일 형식, 희소데이터용 압출 파일이다. 메로리, 처리속도 개선 - 머신러닝에서 활용되는 명식    \n",
    "레이블 행:값 행:값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0f19926-9ebf-4b2f-91b3-452aaf326b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://788ab5d9f938:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>classificationExample2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f001c29c250>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"classificationExample2\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6380b617-6a13-4793-9595-5a33cb0b19c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = spark.read.format('libsvm').load('learning_spark_data/sample_libsvm_data.txt')\n",
    "data2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b23cab1-7a18-49e0-82f2-cf80d7b67bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbc34a56-8a36-466d-a6f2-790891a7fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data2.randomSplit([0.7, 0.3], seed=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "488a18b5-598a-444b-8516-797191c31b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 27)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.count(), test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4597eca-184f-4c59-97fe-2c3745d048de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[98,99,100,1...|[0.95414441393043...|[0.72194788886091...|       0.0|\n",
      "|  0.0|(692,[100,101,102...|[0.48568919283978...|[0.61909039185191...|       0.0|\n",
      "|  0.0|(692,[123,124,125...|[1.00961478127974...|[0.73294475454830...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[0.90293696106823...|[0.71155267489794...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[0.75830339388632...|[0.68098526895593...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[0.97194839391749...|[0.72550768363690...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[0.88414239930651...|[0.70767989197633...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[0.96585465524705...|[0.72429247205628...|       0.0|\n",
      "|  0.0|(692,[128,129,130...|[0.91063904393044...|[0.71313091310478...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[0.67037454557081...|[0.66158702114842...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lrModel = lr.fit(train_data)\n",
    "pred = lrModel.transform(test_data)\n",
    "pred.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6cb9c98-54d4-4234-a333-77fc64c70a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = BinaryClassificationEvaluator(metricName='areaUnderROC')\n",
    "auc = eval.evaluate(pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "045c41e1-4e80-4847-bbef-31b7db6877b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f67c6b-51c5-4df2-ba1d-c30751cfee38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e88ad5-6b9a-4fa1-bfe2-814f213d28e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3633f26b-6007-41f6-aae2-b73c8256c759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b7bcf9-8a2a-4f72-b65b-4ef40ead4ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
